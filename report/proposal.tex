\documentclass[11pt,letterpaper]{article}

\usepackage[letterpaper,margin=0.8in,nohead]{geometry}

\usepackage[colorlinks]{hyperref}
\usepackage{url}
\usepackage{breakurl}

\hypersetup{
    colorlinks,
    linkcolor={red},
    citecolor={blue},
    urlcolor={blue}
}

% add packages as needed


\title{CIS 6930: Privacy \& Machine Learning\\
	\large Project Proposal: Deep learning-based approaches for stylometric De-Anonymization for model authorship} %% TODO: replace with the title of your project

%% TODO: your name and email go here (all members of the group)
%% Comment out as needed and designate a point of contact
\author{
        Apoorv Chandurkar \\{\em (Point of Contact)} \\
        apoorvchandurkar@ufl.edu\\
        \and
        Kunwardeep Singh \\
        kunwardeep.singh@ufl.edu\\
}

% set the date to today
\date{\today}


\begin{document} % start document tag

\maketitle


%%% Remember: writing counts! (try to be clear and concise.)
%%% the whole proposal should be about 2 pages (in 11pt font)


%% TODO: write your introduction
%% Must address:
%% - What is the problem?
%% - Why is the problem interested and worth solving?
%% - What are you proposing to do (at high level)?
%%
\section{Introduction}

% TODO:
With rapid advancement in Natural Language Processing and Deep learning, the end-to-end pipeline for many natural language-related tasks is possible. With new architectures for Language modeling achieving very impressive results in Natural Language Generation, neural networks can output coherent text given some textual prompt. Misuse of these models can be done by spreading fake news and malicious content on a large scale. Hence, from a security perspective, it is imperative to treat these models as potential authors and perform a stylometric analysis of the text they are generating to de-anonymize them if they are deployed with a malicious intent. 
\par In our project, we are proposing to develop a Deep-learning based classifier that can classify text generated by the top 4 State of the Art “Language Modelling” open-source models. Our goal is to research how much effect the architecture of a neural network has on its style, if any. We will add another class of human-generated text and examine how much stylistic difference is present between current SoTA Language Models and human-written text. Also, we are planning to investigate the effectiveness of current Stylometry methods on Neural Network generated text to find out if current techniques still work effectively or we need some modified approach for tackling this problem.



%% TODO: write your background and related work
%% Must contain:
%% - Background to make the proposal self-contained
%% - Short related work survey (what are the 3-4 most related papers about? what do they do?)
%% - Why is your proposal novel? What are you proposing to do different?
%%
\section{Background and Related Work}

% TODO:
De-anonymization of anonymous authors through stylometry has been used historically to get literary, historical and criminal investigation breakthroughs. Stylometry was earlier done only manually to identify hidden attributes associated with authors helping in the de-anonymization process. With the advent of machine learning researchers in the security domain have applied machine learning to classify text or attribute authorship based on authorship style or genre. (for eg. Afroz et al. \cite{afroz2014doppelganger}, Ramyaa et al. \cite{ramyaa2004using})  But in these methods, the features based on which classification is done are hand-crafted and extracted manually. Also, Caliskan-Islam et al \cite{caliskan2015anonymizing} used stylometry on programming code to de-anonymize programmers who authored the source code using a Random Forest based classifier. Many papers use stylometry to only predict some personal attributes of the author like gender and/or age etc.(for eg. Sarawgi et al. \cite{sarawgi2011gender},  Surendran et al.\cite{surendran2017stylometry}). 
\par We are proposing to use Deep Learning to classify input text without any completely manual feature extraction method. Also, we are proposing a novel idea of treating AI-models as authors and differentiating between their stylometric style along with researching style differences between humans and Language models.



%% TODO: write your proposed approach and describe your plan
%%
%% - Describe your approach to solve the problem
%% - What's your plan?
%% - Be concrete!!
%% 		-- What dataset will you use?
%% 		-- What equipment do you need? How will you get it?
%% 		-- What are you going to measure?
%%		-- How will you know whether what you are doing is working?
%% 
\section{Proposed Approach \& Plan}

% TODO:
We plan to approach our problem in the following phases:
 \begin{enumerate}
   \item Model selection
   \begin{enumerate}
     \item There are many open-source Natural Language Generation models trained on a specific dataset and specific task with different architecture. We are planning to focus on Language Modelling neural networks that are tasked to predict the next word in a sentence given a sequence of prior occurring word tokens (eg. GPT-2). We plan to pick Top 4 (this top-k parameter can vary) State of The Art models in Language modeling with papers and code can be seen here for reference - https://paperswithcode.com/task/language-modelling. Also, open-source code for various these models is available here: https://github.com/huggingface/transformers. We examine and select the best performing models and also consider architecture and other factors while finalizing them as classes in our classification task.
   \end{enumerate}

   \item Training data gathering
   \begin{enumerate}
     \item OpenAI has open-sourced its GPT-2 output dataset (https://github.com/openai/gpt-2-output-dataset). Similarly, we are planning to run the pre-trained models to generate prompts and collect sufficient data and label them to assemble training data required to train our classifier.
     \item Human-generated text datasets are readily available. (for eg. https://github.com/niderhoff/nlp-datasets)
   \end{enumerate}

   \item Design and development of neural network-based classifier.
   \begin{enumerate}
     \item During and after the training data gathering phase we are planning to start the development of our classifier neural network.
     \item We are planning to build an lstm based classifier, but we will finalize architecture and hyper-parameters after some initial experiments and preliminary findings.
   \end{enumerate}

   \item Evaluation and findings
   \begin{enumerate}
     \item After sufficient training, We will quantitatively examine the accuracy of our classifier and determine the extent to which stylometric difference is present in different neural networks.
     \item Also, we will qualitatively examine the extent to which architecture, content of text (sports, politics, science, art) determines stylometric differences between various models.
   \end{enumerate}

 \end{enumerate}


%% TODO: Write a short timeline of your project
%%
%% - Describe steps and milestones for you project
%% - Briefly state what you hope the final outcome will be. (Will you have preliminary results to include on the presentation/poster?)
%%
%%
%% Keep in mind the project milestones must include mid semester report
%%
\section{Timeline}

% TODO:
\begin{center}
{\renewcommand{\arraystretch}{1.2}
\begin{tabular}{|l|c|}
\hline
\multicolumn{1}{|c|}{\textbf{Milestone}}         & \textbf{Target Date} \\ \hline
Evaluate and select models based on performance  & 10/11/2019           \\ \hline
Gather and clean the dataset                     & 10/18/2019           \\ \hline
Start developing the classifier                  & 10/25/2019           \\ \hline
Submit mid semester project report               & 10/31/2019           \\ \hline
Incorporate feedback received in the project     & 11/08/2019           \\ \hline
Optimize the classifier after several iterations & 11/22/2019           \\ \hline
Start evaluation and gather results              & 11/29/2019           \\ \hline
Final Project Report                             & 12/11/2019           \\ \hline
\end{tabular}
}
\end{center}

\bibliographystyle{ieeetr}
\bibliography{References}


\end{document} % end tag of the document